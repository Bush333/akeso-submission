{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8882920,"sourceType":"datasetVersion","datasetId":5345395},{"sourceId":8893813,"sourceType":"datasetVersion","datasetId":5348333},{"sourceId":8897885,"sourceType":"datasetVersion","datasetId":5349682},{"sourceId":8898290,"sourceType":"datasetVersion","datasetId":5349817},{"sourceId":8938406,"sourceType":"datasetVersion","datasetId":5378010},{"sourceId":8955493,"sourceType":"datasetVersion","datasetId":5389608}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NOTE :\n### 1. Models trained/evaluated in final_ptge.ipynb havce been saved and then loaded. Pretrained models have been used here, hence please change the path to the pretrained models accordingly. We can also merge this code with the final_ptge.ipynb if we dont want to use pretrained models.\n### 2. One can download my pretrained models as well. Details are provided in README.md\n\n### 3. Due to limited compute and storage resources, we have considered to process and work with only 3 subjects [p00,p01,p02]. For the leave-out strategy we have used only p00\n### 4. Make sure you have already executed \"python3 prepare_and_process_data.py\". This will created \"processed\" folder need to run this notebook\n","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow==2.15.1","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-07-16T00:54:21.109335Z","iopub.execute_input":"2024-07-16T00:54:21.109602Z","iopub.status.idle":"2024-07-16T00:55:20.972133Z","shell.execute_reply.started":"2024-07-16T00:54:21.109578Z","shell.execute_reply":"2024-07-16T00:55:20.970911Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.15.1\n  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (16.0.6)\nCollecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow==2.15.1)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.15.1) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.2.2)\nDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ml-dtypes, keras, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.2.0\n    Uninstalling ml-dtypes-0.2.0:\n      Successfully uninstalled ml-dtypes-0.2.0\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.3.2 tensorflow-2.15.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tf-models-official==2.15","metadata":{"execution":{"iopub.status.busy":"2024-07-16T00:57:47.473822Z","iopub.execute_input":"2024-07-16T00:57:47.474262Z","iopub.status.idle":"2024-07-16T00:58:09.135578Z","shell.execute_reply.started":"2024-07-16T00:57:47.474229Z","shell.execute_reply":"2024-07-16T00:58:09.134035Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tf-models-official==2.15\n  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: Cython in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (3.0.8)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (9.5.0)\nCollecting gin-config (from tf-models-official==2.15)\n  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (2.136.0)\nCollecting immutabledict (from tf-models-official==2.15)\n  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: kaggle>=1.3.9 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (1.6.14)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (3.7.5)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (1.26.4)\nRequirement already satisfied: oauth2client in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (4.1.3)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (4.10.0.84)\nRequirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (2.2.2)\nRequirement already satisfied: psutil>=5.4.3 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (5.9.3)\nRequirement already satisfied: py-cpuinfo>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (9.0.0)\nCollecting pycocotools (from tf-models-official==2.15)\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: pyyaml>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (6.0.1)\nCollecting sacrebleu (from tf-models-official==2.15)\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (1.11.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (0.2.0)\nCollecting seqeval (from tf-models-official==2.15)\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (1.16.0)\nRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (4.9.4)\nRequirement already satisfied: tensorflow-hub>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (0.16.1)\nCollecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.15)\n  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\nRequirement already satisfied: tensorflow-text~=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (2.15.0)\nRequirement already satisfied: tensorflow~=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tf-models-official==2.15) (2.15.1)\nCollecting tf-slim>=1.1.0 (from tf-models-official==2.15)\n  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15) (0.21.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15) (2.26.1)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15) (2.11.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15) (3.0.1)\nRequirement already satisfied: certifi>=2023.7.22 in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15) (2024.7.4)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15) (2.9.0.post0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15) (4.66.4)\nRequirement already satisfied: python-slugify in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15) (8.0.4)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15) (1.26.18)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15) (6.1.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->tf-models-official==2.15) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.22.0->tf-models-official==2.15) (2023.4)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (69.0.3)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15) (2.15.0)\nRequirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.15) (2.15.1)\nRequirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.15) (0.1.8)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.15) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.15) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.15) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.15) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->tf-models-official==2.15) (3.1.1)\nRequirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15) (0.5.1)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15) (0.3.0)\nRequirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15) (4.9)\nCollecting portalocker (from sacrebleu->tf-models-official==2.15)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official==2.15) (2023.12.25)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official==2.15) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official==2.15) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu->tf-models-official==2.15) (5.2.2)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval->tf-models-official==2.15) (1.2.2)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15) (8.1.7)\nRequirement already satisfied: etils>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.15) (1.6.0)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15) (2.3)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15) (0.14.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15) (0.10.2)\nRequirement already satisfied: array-record>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15) (0.5.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official==2.15) (0.42.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.15) (2024.5.0)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.15) (6.1.1)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official==2.15) (3.17.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.15) (1.62.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.15) (4.2.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle>=1.3.9->tf-models-official==2.15) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle>=1.3.9->tf-models-official==2.15) (3.6)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15) (3.2.0)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15) (3.0.3)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.15) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.10/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.15) (1.3)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15) (2.1.3)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15) (3.2.2)\nDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=279501be88296f9bd6843b17bcad2205382e0aea40096bd47219c6b3237d4fa8\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: gin-config, tf-slim, tensorflow-model-optimization, portalocker, immutabledict, sacrebleu, seqeval, pycocotools, tf-models-official\nSuccessfully installed gin-config-0.5.0 immutabledict-4.2.0 portalocker-2.10.1 pycocotools-2.0.8 sacrebleu-2.4.2 seqeval-1.2.2 tensorflow-model-optimization-0.8.0 tf-models-official-2.15.0 tf-slim-1.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\ntf.version.VERSION","metadata":{"execution":{"iopub.status.busy":"2024-07-16T00:58:35.254267Z","iopub.execute_input":"2024-07-16T00:58:35.254619Z","iopub.status.idle":"2024-07-16T00:58:41.014348Z","shell.execute_reply.started":"2024-07-16T00:58:35.254592Z","shell.execute_reply":"2024-07-16T00:58:41.013411Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-07-16 00:58:35.671468: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-16 00:58:35.671527: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-16 00:58:35.673062: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'2.15.1'"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom sklearn.metrics import mean_absolute_error\nimport random\nimport numpy as np\nimport os, glob\nfrom tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Input\nfrom tensorflow.keras.models import Model\nfrom PIL import Image\n\ngpus=tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu,True)\nprint(gpus)\nimport matplotlib.pyplot as plt\n\n# Ensure the same seed for reproducibility\nrandom.seed(12)\nnp.random.seed(12)\ntf.random.set_seed(12)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T00:59:13.835722Z","iopub.execute_input":"2024-07-16T00:59:13.836602Z","iopub.status.idle":"2024-07-16T00:59:14.451693Z","shell.execute_reply.started":"2024-07-16T00:59:13.836567Z","shell.execute_reply":"2024-07-16T00:59:14.450753Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-07-16T00:59:37.126625Z","iopub.execute_input":"2024-07-16T00:59:37.127310Z","iopub.status.idle":"2024-07-16T00:59:37.131370Z","shell.execute_reply.started":"2024-07-16T00:59:37.127274Z","shell.execute_reply":"2024-07-16T00:59:37.130506Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nfrom PIL import Image\n\n\n# Define custom Huber loss function\ndef custom_huber_loss(y_true, y_pred, delta=1.5):\n    error = y_true - y_pred\n    is_small_error = tf.abs(error) <= delta\n\n    small_error_loss = tf.square(error) / 2\n    big_error_loss = delta * (tf.abs(error) - delta / 2)\n\n    return tf.where(is_small_error, small_error_loss, big_error_loss)\n\n\n# Calculate gaze loss as the average of Huber losses\ndef gaze_loss(y_true, y_pred, delta=1.5):\n    huber_losses = custom_huber_loss(y_true, y_pred, delta)\n    return tf.reduce_mean(huber_losses)\n\n# Function to preprocess the images\ndef preprocess_image(image, target_size):\n    image = tf.image.resize(image, target_size)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# Define the GazeDataset class\nclass GazeDataset(tf.data.Dataset):\n    def __new__(cls, subject_to_leave_out=None, batch_size=8, validation=False):\n        def _generator():\n            root_dir = 'processed_data'\n            subjects = ['p00', 'p01', 'p02']\n            transform_face = lambda img: preprocess_image(img, (224, 224))\n            transform_eye = lambda img: preprocess_image(img, (112, 112))\n\n            for subject in subjects:\n                if validation:\n                    if subject != subject_to_leave_out:\n                        continue\n                else:\n                    if subject == subject_to_leave_out:\n                        continue\n                \n                person_dir = os.path.join(root_dir, 'Image', subject)\n                for image_name in os.listdir(os.path.join(person_dir, 'face')):\n                    face_image_path = os.path.join(person_dir, 'face', image_name)\n                    left_eye_image_path = os.path.join(person_dir, 'lefteye', image_name)\n                    right_eye_image_path = os.path.join(person_dir, 'righteye', image_name)\n                    rotation_matrix_path = os.path.join(person_dir, 'rotation_matrix', image_name.replace('.jpg', '.npy'))\n                    rotation_matrix_flipped_path = os.path.join(person_dir, 'rotation_matrix_flipped', image_name.replace('.jpg', '.npy'))\n                    gaze_2d_path = os.path.join(person_dir, '2d_gaze', image_name.replace('.jpg', '.npy'))\n                    gaze_3d_path = os.path.join(person_dir, '3d_gaze', image_name.replace('.jpg', '.npy'))\n                    gaze_3d_flipped_path = os.path.join(person_dir, '3d_gaze_flipped', image_name.replace('.jpg', '.npy'))\n                    eye_coords_path = os.path.join(person_dir, 'eye_coords', image_name.replace('.jpg', '.npy'))\n\n                    face_image = Image.open(face_image_path).convert('RGB')\n                    left_eye_image = Image.open(left_eye_image_path).convert('RGB')\n                    right_eye_image = Image.open(right_eye_image_path).convert('RGB')\n\n                    face_image = transform_face(np.array(face_image))\n                    left_eye_image = transform_eye(np.array(left_eye_image))\n                    right_eye_image = transform_eye(np.array(right_eye_image))\n\n                    rotation_matrix = np.load(rotation_matrix_path).astype(np.float32)\n                    rotation_matrix_flipped = np.load(rotation_matrix_flipped_path).astype(np.float32)\n                    gaze_2d = np.load(gaze_2d_path).astype(np.float32)\n                    gaze_3d = np.load(gaze_3d_path).astype(np.float32)\n                    gaze_3d_flipped = np.load(gaze_3d_flipped_path).astype(np.float32)\n                    eye_coords = np.load(eye_coords_path).astype(np.float32)\n\n                    yield face_image, left_eye_image, right_eye_image, rotation_matrix, rotation_matrix_flipped, gaze_2d, gaze_3d, gaze_3d_flipped, eye_coords, subject\n\n        return tf.data.Dataset.from_generator(\n            _generator,\n            output_signature=(\n                tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n                tf.TensorSpec(shape=(112, 112, 3), dtype=tf.float32),\n                tf.TensorSpec(shape=(112, 112, 3), dtype=tf.float32),\n                tf.TensorSpec(shape=(3, 3), dtype=tf.float32),\n                tf.TensorSpec(shape=(3, 3), dtype=tf.float32),\n                tf.TensorSpec(shape=(2,), dtype=tf.float32),\n                tf.TensorSpec(shape=(3,), dtype=tf.float32),\n                tf.TensorSpec(shape=(3,), dtype=tf.float32),\n                tf.TensorSpec(shape=(6,), dtype=tf.float32),\n                tf.TensorSpec(shape=(), dtype=tf.string)\n            )\n        ).batch(batch_size)\n\n# Testing the dataset\nval_dataloader = GazeDataset(subject_to_leave_out='p00', batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T00:59:45.124493Z","iopub.execute_input":"2024-07-16T00:59:45.124893Z","iopub.status.idle":"2024-07-16T00:59:45.329539Z","shell.execute_reply.started":"2024-07-16T00:59:45.124863Z","shell.execute_reply":"2024-07-16T00:59:45.328560Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Analysis of Angular Errors","metadata":{}},{"cell_type":"code","source":"gaze_model = tf.keras.models.load_model('/kaggle/input/pretrained-models/gaze_model_with_leaveout_p00/kaggle/working/gaze_model_with_leaveout_p00', compile=False)\ncalibration_model = tf.keras.models.load_model('/kaggle/input/pretrained-models/calibration_model_with_leaveout_p00/kaggle/working/calibration_model_with_leaveout_p00', compile=False)\nspaze_model = tf.keras.models.load_model('/kaggle/input/pretrained-models/spaze_model_with_leaveout_p00/kaggle/working/spaze_model_with_leaveout_p00', compile=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T00:59:49.203496Z","iopub.execute_input":"2024-07-16T00:59:49.203892Z","iopub.status.idle":"2024-07-16T01:00:34.891255Z","shell.execute_reply.started":"2024-07-16T00:59:49.203862Z","shell.execute_reply":"2024-07-16T01:00:34.890258Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Uncomment this cell, if you dont havent run prepare_and_process_data.py, and no 'processed_data' directory exists\n\n# \"\"\"\n# src file for preparing data from MPIIFaceGaze and MPIIGaze directories\n# \"\"\"\n# import importlib.util\n# import sys\n\n# # Path to preprocessing.py\n# file_path = '/kaggle/input/preprocess/preprocessing.py'\n\n# # Load the module\n# spec = importlib.util.spec_from_file_location(\"dpc\", file_path)\n# dpc = importlib.util.module_from_spec(spec)\n# sys.modules[\"dpc\"] = dpc\n# spec.loader.exec_module(dpc)\n\n# # Now you can import preprocessing.py\n# #import preprocessing as dpc\n# import numpy as np\n# import scipy.io as sio\n# #import content as dpy\n# import cv2\n# import os\n# import sys\n\n# #import preprocessing as dpc\n# import linecache\n# root = \"/kaggle/input/mpiigaze/MPIIFaceGaze/MPIIFaceGaze\"\n# sample_root = \"/kaggle/input/mpiigaze/MPIIGaze/MPIIGaze/Evaluation Subset/sample list for eye image\"\n# out_root = \"processed_data\"\n# scale = True\n# MPII_path=\"/kaggle/input/mpiigaze/MPIIGaze/MPIIGaze/Data/Original\"\n\n# def ImageProcessing_MPII():\n#     persons = os.listdir(sample_root)\n#     persons.sort()\n#     for person in persons[:3]:\n#         sample_list = os.path.join(sample_root, person)\n\n#         person = person.split(\".\")[0]\n#         im_root = os.path.join(root, person)\n#         anno_path = os.path.join(root, person, f\"{person}.txt\")\n\n#         im_outpath = os.path.join(out_root, \"Image\", person)\n#         label_outpath = os.path.join(out_root, \"Label\", f\"{person}.label\")\n\n#         if not os.path.exists(im_outpath):\n#             os.makedirs(im_outpath)\n#         if not os.path.exists(os.path.join(out_root, \"Label\")):\n#             os.makedirs(os.path.join(out_root, \"Label\"))\n\n#         print(f\"Start Processing {person}\")\n#         ImageProcessing_Person(im_root, anno_path, sample_list, im_outpath, label_outpath, person)\n\n\n\n# def ImageProcessing_Person(im_root, anno_path, sample_list, im_outpath, label_outpath, person):\n#     # Read camera matrix\n#     camera = sio.loadmat(os.path.join(f\"{im_root}\", \"Calibration\", \"Camera.mat\"))\n#     camera = camera[\"cameraMatrix\"]\n\n#     # Read gaze annotation\n#     annotation = os.path.join(anno_path)\n#     with open(annotation) as infile:\n#         anno_info = infile.readlines()\n#     anno_dict = {line.split(\" \")[0]: line.strip().split(\" \")[1:-1] for line in anno_info}\n\n#     # Create the handle of label\n#     outfile = open(label_outpath, 'w')\n#     outfile.write(\"Face Left Right Origin WhichEye 3DGaze 3DHead 2DGaze 2DHead Rmat Smat GazeOrigin\\n\")\n#     subdirs=['face',\n#              'lefteye',\n#              'righteye',\n#              'rotation_matrix',\n#              'rotation_matrix_flipped',\n#              '3d_gaze',\n#              '3d_gaze_flipped',\n#              '2d_gaze',\n#              'eye_coords']\n#     for directory in subdirs:\n#         if not os.path.exists(os.path.join(im_outpath,directory)):\n#             os.makedirs(os.path.join(im_outpath,directory))\n\n#     with open(sample_list) as infile:\n#         im_list = infile.readlines()\n#         total = len(im_list)\n\n#     for count, info in enumerate(im_list):\n\n#         progressbar = \"\".join([\"\\033[41m%s\\033[0m\" % '   '] * int(count/total * 20))\n#         progressbar = \"\\r\" + progressbar + f\" {count}|{total}\"\n#         print(progressbar, end = \"\", flush=True)\n\n#         # Read image info\n#         im_info, which_eye = info.strip().split(\" \")\n#         day, im_name = im_info.split(\"/\")\n#         im_number = int(im_name.split(\".\")[0])\n\n#         # Read image annotation and image\n#         im_path = os.path.join(im_root, day, im_name)\n#         im = cv2.imread(im_path)\n#         annotation = anno_dict[im_info]\n#         annotation = AnnoDecode(annotation)\n#         origin = annotation[\"facecenter\"]\n\n#         # Normalize the image\n#         norm = dpc.norm(center = annotation[\"facecenter\"],\n#                         gazetarget = annotation[\"target\"],\n#                         headrotvec = annotation[\"headrotvectors\"],\n#                         imsize = (224, 224),\n#                         camparams = camera)\n\n#         im_face = norm.GetImage(im)\n\n#         # Crop left eye images\n#         llc = norm.GetNewPos(annotation[\"left_left_corner\"])\n#         lrc = norm.GetNewPos(annotation[\"left_right_corner\"])\n#         im_left = norm.CropEye(llc, lrc)\n#         im_left = dpc.EqualizeHist(im_left)\n\n#         # Crop Right eye images\n#         rlc = norm.GetNewPos(annotation[\"right_left_corner\"])\n#         rrc = norm.GetNewPos(annotation[\"right_right_corner\"])\n#         im_right = norm.CropEye(rlc, rrc)\n#         im_right = dpc.EqualizeHist(im_right)\n\n#         # Acquire essential info\n#         gaze = norm.GetGaze(scale=scale)\n#         head = norm.GetHeadRot(vector=True)\n#         origin = norm.GetCoordinate(annotation[\"facecenter\"])\n#         rvec, svec = norm.GetParams()\n\n#         # flip the images when it is right eyes\n#         if which_eye == \"left\":\n#             pass\n#         elif which_eye == \"right\":\n#             im_face = cv2.flip(im_face, 1)\n#             im_left = cv2.flip(im_left, 1)\n#             im_right = cv2.flip(im_right, 1)\n\n#             temp = im_left\n#             im_left = im_right\n#             im_right = temp\n\n#             gaze = dpc.GazeFlip(gaze)\n#             head = dpc.HeadFlip(head)\n#             origin[0] = -origin[0]\n\n#         gaze_2d = dpc.GazeTo2d(gaze)\n#         head_2d = dpc.HeadTo2d(head)\n\n#         # Save the acquired info\n#         cv2.imwrite(os.path.join(im_outpath, \"face\", str(count+1)+\".jpg\"), im_face)\n#         cv2.imwrite(os.path.join(im_outpath, \"lefteye\", str(count+1)+\".jpg\"), im_left)\n#         cv2.imwrite(os.path.join(im_outpath, \"righteye\", str(count+1)+\".jpg\"), im_right)\n#         rotation_matrix=norm.GetHeadRot(vector=False)\n#         rotation_matrix_flipped=dpc.FlipRot(head)\n#         _3d_gaze_flipped=dpc.GazeFlip(gaze)\n\n#         np.save(os.path.join(im_outpath,'rotation_matrix',str(count+1)+'.npy'), rotation_matrix)\n#         np.save(os.path.join(im_outpath,'rotation_matrix_flipped',str(count+1)+'.npy'), rotation_matrix_flipped)\n#         np.save(os.path.join(im_outpath,'2d_gaze',str(count+1)+'.npy'), gaze_2d)\n#         np.save(os.path.join(im_outpath,'3d_gaze',str(count+1)+'.npy'), gaze)\n#         np.save(os.path.join(im_outpath,'3d_gaze_flipped',str(count+1)+'.npy'), _3d_gaze_flipped)\n#         save_name_face = os.path.join(person, \"face\", str(count+1) + \".jpg\")\n#         save_name_left = os.path.join(person, \"lefteye\", str(count+1) + \".jpg\")\n#         save_name_right = os.path.join(person, \"righteye\", str(count+1) + \".jpg\")\n\n#         save_origin = im_info\n#         save_flag = which_eye\n#         save_gaze = \",\".join(gaze.astype(\"str\"))\n#         save_head = \",\".join(head.astype(\"str\"))\n#         save_gaze2d = \",\".join(gaze_2d.astype(\"str\"))\n#         save_head2d = \",\".join(head_2d.astype(\"str\"))\n#         save_rvec = \",\".join(rvec.astype(\"str\"))\n#         save_svec = \",\".join(svec.astype(\"str\"))\n#         origin = \",\".join(origin.astype(\"str\"))\n\n#         save_str = \" \".join([save_name_face, save_name_left, save_name_right, save_origin, save_flag, save_gaze, save_head, save_gaze2d, save_head2d, save_rvec, save_svec, origin])\n\n#         outfile.write(save_str + \"\\n\")\n#         # print(im_root,im_number,im_name,day)\n#         eye_coord_file=f'{MPII_path}/{person}/{day}/annotation.txt'\n#         # print(eye_coord_file)\n#         coords=linecache.getline(eye_coord_file,im_number).split(' ')[-6:]\n#         coords[-1]=coords[-1][:-1]\n#         coords=np.array(list(map(float,coords)))\n#         np.save(os.path.join(im_outpath,'eye_coords',str(count+1)+'.npy'), coords)\n\n#     print(\"\")\n#     outfile.close()\n\n\n# def AnnoDecode(anno_info):\n# \tannotation = np.array(anno_info).astype(\"float32\")\n# \tout = {}\n# \tout[\"left_left_corner\"] = annotation[2:4]\n# \tout[\"left_right_corner\"] = annotation[4:6]\n# \tout[\"right_left_corner\"] = annotation[6:8]\n# \tout[\"right_right_corner\"] = annotation[8:10]\n# \tout[\"headrotvectors\"] = annotation[14:17]\n# \tout[\"headtransvectors\"] = annotation[17:20]\n# \tout[\"facecenter\"] = annotation[20:23]\n# \tout[\"target\"] = annotation[23:26]\n# \treturn out\n\n\n# if __name__ == \"__main__\":\n#     ImageProcessing_MPII()","metadata":{"execution":{"iopub.status.busy":"2024-07-15T23:43:01.413695Z","iopub.status.idle":"2024-07-15T23:43:01.414294Z","shell.execute_reply.started":"2024-07-15T23:43:01.414051Z","shell.execute_reply":"2024-07-15T23:43:01.414072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing Model's robustness in handling variations in calibration parameters","metadata":{}},{"cell_type":"code","source":"# Calculate angular error\ndef compute_angular_error(y_true, y_pred):\n    y_true = tf.nn.l2_normalize(y_true, axis=-1)\n    y_pred = tf.nn.l2_normalize(y_pred, axis=-1)\n    dot_product = tf.reduce_sum(tf.multiply(y_true, y_pred), axis=-1)\n    angular_error = tf.acos(tf.clip_by_value(dot_product, -1.0, 1.0))\n    return tf.reduce_mean(angular_error) * (180.0 / np.pi)\n\n# Define the evaluation function with calibration variations for angular error\ndef evaluate_model_with_calibration_variations_angular_error(model, dataloader, model_type='ptge', variation_range=(-0.1, 0.1)):\n    total_error = 0.0\n    num_batches = 0\n    results = []\n\n    for i, (face_image, left_eye_image, right_eye_image, rotation_matrix, rotation_matrix_flipped, gaze_2d, gaze_3d, gaze_3d_flipped, eye_coords, subject_id) in enumerate(dataloader):\n        # Apply variations to calibration parameters (rotation_matrix)\n        variation = np.random.uniform(variation_range[0], variation_range[1], rotation_matrix.shape)\n        varied_rotation_matrix = rotation_matrix + variation\n\n        subject_indices = [int(s.decode().split('p')[1]) for s in subject_id.numpy()]\n\n        input_dict = {\n            'eye_coords': tf.convert_to_tensor(eye_coords, dtype=tf.float32),\n            'face': tf.convert_to_tensor(face_image, dtype=tf.float32),\n            'flipped_face': tf.convert_to_tensor(tf.image.flip_left_right(face_image), dtype=tf.float32),\n            'id': tf.convert_to_tensor(subject_indices, dtype=tf.int32),\n            'lefteye': tf.convert_to_tensor(left_eye_image, dtype=tf.float32),\n            'righteye': tf.convert_to_tensor(right_eye_image, dtype=tf.float32),\n            'rotation_matrix': tf.convert_to_tensor(varied_rotation_matrix, dtype=tf.float32)\n        }\n\n        calibration_input_dict = input_dict.copy()\n        calibration_input_dict['rotation_matrix_flipped'] = tf.convert_to_tensor(rotation_matrix_flipped, dtype=tf.float32)\n\n        try:\n            if model_type == 'ptge':\n                # First, get the initial gaze estimation from the Gaze Model\n                initial_gaze_estimation = model['gaze_model'](input_dict)\n\n                # Now, use the Calibration Model to refine the gaze estimation\n                calibration_input_dict['gaze'] = initial_gaze_estimation\n                calibration_input_dict['gaze_flipped'] = initial_gaze_estimation  # No flipping, use as is\n\n                refined_gaze_estimation = model['calibration_model'](calibration_input_dict)\n\n                # Ensure the refined_gaze_estimation shape matches the gaze_3d shape\n                refined_gaze_estimation = refined_gaze_estimation[:, :3]  # Only take the first 3 columns\n\n                # Calculate angular error\n                angular_error = compute_angular_error(gaze_3d, refined_gaze_estimation)\n                results.append((gaze_3d.numpy(), refined_gaze_estimation.numpy()))\n\n            elif model_type == 'spaze':\n                # Get the gaze estimation from the SPAZE Model\n                spaze_gaze_estimation = model['spaze_model'](face_image, training=False)\n\n                # Calculate angular error\n                angular_error = compute_angular_error(gaze_2d, spaze_gaze_estimation)\n                results.append((gaze_2d.numpy(), spaze_gaze_estimation.numpy()))\n\n            total_error += angular_error.numpy()\n            num_batches += 1\n\n        except Exception as e:\n            print(f\"Error during gaze model prediction: {str(e)}\")\n            continue\n\n    average_error = total_error / num_batches if num_batches > 0 else float('inf')\n    return average_error, results\n\n# Define the function to evaluate both models and save results\ndef evaluate_and_save_angular_error_results(subjects, variation_ranges):\n    # Initialize the results dictionary\n    results = {\n        'variation_range': [],\n        'ptge_angular_error': [],\n        'spaze_angular_error': [],\n    }\n\n    for subject in subjects:\n        print(f\"Evaluating for subject: {subject}\")\n        val_dataloader = GazeDataset(subject_to_leave_out=subject, batch_size=8)\n\n        for variation_range in variation_ranges:\n            print(f\"Evaluating with variation range: {variation_range}\")\n\n            # Evaluate PTGE model with calibration variations for angular error\n            ptge_angular_error, _ = evaluate_model_with_calibration_variations_angular_error(\n                {'gaze_model': gaze_model, 'calibration_model': calibration_model}, \n                val_dataloader, \n                model_type='ptge', \n                variation_range=variation_range\n            )\n            # Print PTGE angular error\n            print(f\"PTGE Angular Error for variation range {variation_range}: {ptge_angular_error}\")\n            \n            # Evaluate SPAZE model with calibration variations for angular error\n            spaze_angular_error, _ = evaluate_model_with_calibration_variations_angular_error(\n                {'spaze_model': spaze_model}, \n                val_dataloader, \n                model_type='spaze', \n                variation_range=variation_range\n            )\n            # Print SPAZE angular error\n            print(f\"SPAZE Angular Error for variation range {variation_range}: {spaze_angular_error}\")\n            \n            results['variation_range'].append(variation_range)\n            results['ptge_angular_error'].append(ptge_angular_error)\n            results['spaze_angular_error'].append(spaze_angular_error)\n\n    # Convert the results to a DataFrame and save\n    df_results = pd.DataFrame(results)\n    df_results.to_csv('ptge_spaze_angular_error_results-variations-calibration-params.csv', index=False)\n    print(\"Results saved to 'ptge_spaze_angular_error_results-variations-calibration-params.csv'.\")\n\n# Define subjects and variation ranges\nsubjects = ['p00']\nvariation_ranges = [(-0.1, 0.1), (-0.2, 0.2), (-0.3, 0.3)]\n\n# Evaluate and save results\nevaluate_and_save_angular_error_results(subjects, variation_ranges)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T01:00:52.182724Z","iopub.execute_input":"2024-07-16T01:00:52.183205Z","iopub.status.idle":"2024-07-16T01:08:10.308282Z","shell.execute_reply.started":"2024-07-16T01:00:52.183168Z","shell.execute_reply":"2024-07-16T01:08:10.307300Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Evaluating for subject: p00\nEvaluating with variation range: (-0.1, 0.1)\nPTGE Angular Error for variation range (-0.1, 0.1): 96.10783111572266\nSPAZE Angular Error for variation range (-0.1, 0.1): 79.62430246988933\nEvaluating with variation range: (-0.2, 0.2)\nPTGE Angular Error for variation range (-0.2, 0.2): 96.10786414591472\nSPAZE Angular Error for variation range (-0.2, 0.2): 79.62430246988933\nEvaluating with variation range: (-0.3, 0.3)\nPTGE Angular Error for variation range (-0.3, 0.3): 96.10500227864583\nSPAZE Angular Error for variation range (-0.3, 0.3): 79.62430246988933\nResults saved to 'ptge_spaze_angular_error_results-variations-calibration-params.csv'.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Analyzing Model's robustness with clean data and in handling corrupted data","metadata":{}},{"cell_type":"code","source":"\n# Define the evaluation function\ndef evaluate_model_angular_error(model, dataloader, corruption=None, model_type='ptge'):\n    total_angular_error = 0.0\n    num_batches = 0\n    results = []\n\n    for i, (face_image, left_eye_image, right_eye_image, rotation_matrix, rotation_matrix_flipped, gaze_2d, gaze_3d, gaze_3d_flipped, eye_coords, subject_id) in enumerate(dataloader):\n        if corruption == 'noise':\n            face_image += tf.random.normal(face_image.shape, mean=0.0, stddev=0.1)\n            left_eye_image += tf.random.normal(left_eye_image.shape, mean=0.0, stddev=0.1)\n            right_eye_image += tf.random.normal(right_eye_image.shape, mean=0.0, stddev=0.1)\n        elif corruption == 'blur':\n            face_image = tf.nn.conv2d(face_image, tf.random.normal((3, 3, 3, 3), mean=0.0, stddev=1.0), strides=[1, 1, 1, 1], padding='SAME')\n            left_eye_image = tf.nn.conv2d(left_eye_image, tf.random.normal((3, 3, 3, 3), mean=0.0, stddev=1.0), strides=[1, 1, 1, 1], padding='SAME')\n            right_eye_image = tf.nn.conv2d(right_eye_image, tf.random.normal((3, 3, 3, 3), mean=0.0, stddev=1.0), strides=[1, 1, 1, 1], padding='SAME')\n\n        subject_indices = [int(s.decode().split('p')[1]) for s in subject_id.numpy()]\n\n        input_dict = {\n            'eye_coords': tf.convert_to_tensor(eye_coords, dtype=tf.float32),\n            'face': tf.convert_to_tensor(face_image, dtype=tf.float32),\n            'flipped_face': tf.convert_to_tensor(tf.image.flip_left_right(face_image), dtype=tf.float32),\n            'id': tf.convert_to_tensor(subject_indices, dtype=tf.int32),\n            'lefteye': tf.convert_to_tensor(left_eye_image, dtype=tf.float32),\n            'righteye': tf.convert_to_tensor(right_eye_image, dtype=tf.float32),\n            'rotation_matrix': tf.convert_to_tensor(rotation_matrix, dtype=tf.float32),\n        }\n\n        if model_type == 'ptge':\n            input_tuple = (input_dict,)\n            initial_gaze_estimation = model['gaze_model'](*input_tuple, training=False)\n\n            calibration_input_dict = input_dict.copy()\n            calibration_input_dict.update({\n                'gaze': initial_gaze_estimation,\n                'gaze_flipped': initial_gaze_estimation,\n                'rotation_matrix_flipped': tf.convert_to_tensor(rotation_matrix_flipped, dtype=tf.float32)\n            })\n\n            calibration_input_tuple = (calibration_input_dict,)\n            refined_gaze_estimation = model['calibration_model'](*calibration_input_tuple, training=False)\n            refined_gaze_estimation = refined_gaze_estimation[:, :3]\n\n            angular_error_value = compute_angular_error(gaze_3d, refined_gaze_estimation)\n            results.append((gaze_3d.numpy(), refined_gaze_estimation.numpy()))\n\n        elif model_type == 'spaze':\n            spaze_gaze_estimation = model['spaze_model'](face_image, training=False)\n            angular_error_value = compute_angular_error(gaze_2d, spaze_gaze_estimation)\n            results.append((gaze_2d.numpy(), spaze_gaze_estimation.numpy()))\n\n        total_angular_error += angular_error_value.numpy()\n        num_batches += 1\n\n    average_angular_error = total_angular_error / num_batches if num_batches > 0 else float('inf')\n    return average_angular_error, results\n\n# Define the function to evaluate both models and save results\ndef evaluate_and_save_angular_error_results(subjects):\n    results = {\n        'subject': [],\n        'ptge_clean_angular_error': [],\n        'ptge_corrupted_angular_error_noise': [],\n        'ptge_corrupted_angular_error_blur': [],\n        'spaze_clean_angular_error': [],\n        'spaze_corrupted_angular_error_noise': [],\n        'spaze_corrupted_angular_error_blur': [],\n    }\n\n    for subject in subjects:\n        print(f\"Evaluating for subject: {subject}\")\n        val_dataloader = GazeDataset(subject_to_leave_out=subject, batch_size=8)\n\n        # Evaluate PTGE model on clean data\n        ptge_clean_angular_error, _ = evaluate_model_angular_error({'gaze_model': gaze_model, 'calibration_model': calibration_model}, val_dataloader, model_type='ptge')\n        print(f\"PTGE Clean Angular Error: {ptge_clean_angular_error}\")\n\n        # Evaluate PTGE model on corrupted data (noise)\n        ptge_corrupted_angular_error_noise, _ = evaluate_model_angular_error({'gaze_model': gaze_model, 'calibration_model': calibration_model}, val_dataloader, corruption='noise', model_type='ptge')\n        print(f\"PTGE Corrupted Angular Error (Noise): {ptge_corrupted_angular_error_noise}\")\n\n        # Evaluate PTGE model on corrupted data (blur)\n        ptge_corrupted_angular_error_blur, _ = evaluate_model_angular_error({'gaze_model': gaze_model, 'calibration_model': calibration_model}, val_dataloader, corruption='blur', model_type='ptge')\n        print(f\"PTGE Corrupted Angular Error (Blur): {ptge_corrupted_angular_error_blur}\")\n\n        # Evaluate SPAZE model on clean data\n        spaze_clean_angular_error, _ = evaluate_model_angular_error({'spaze_model': spaze_model}, val_dataloader, model_type='spaze')\n        print(f\"SPAZE Clean Angular Error: {spaze_clean_angular_error}\")\n\n        # Evaluate SPAZE model on corrupted data (noise)\n        spaze_corrupted_angular_error_noise, _ = evaluate_model_angular_error({'spaze_model': spaze_model}, val_dataloader, corruption='noise', model_type='spaze')\n        print(f\"SPAZE Corrupted Angular Error (Noise): {spaze_corrupted_angular_error_noise}\")\n\n        # Evaluate SPAZE model on corrupted data (blur)\n        spaze_corrupted_angular_error_blur, _ = evaluate_model_angular_error({'spaze_model': spaze_model}, val_dataloader, corruption='blur', model_type='spaze')\n        print(f\"SPAZE Corrupted Angular Error (Blur): {spaze_corrupted_angular_error_blur}\")\n\n        results['subject'].append(subject)\n        results['ptge_clean_angular_error'].append(ptge_clean_angular_error)\n        results['ptge_corrupted_angular_error_noise'].append(ptge_corrupted_angular_error_noise)\n        results['ptge_corrupted_angular_error_blur'].append(ptge_corrupted_angular_error_blur)\n        results['spaze_clean_angular_error'].append(spaze_clean_angular_error)\n        results['spaze_corrupted_angular_error_noise'].append(spaze_corrupted_angular_error_noise)\n        results['spaze_corrupted_angular_error_blur'].append(spaze_corrupted_angular_error_blur)\n\n    # Convert the results to a DataFrame and save\n    df_results = pd.DataFrame(results)\n    df_results.to_csv('ptge_spaze_angular_error_results-clean-corrupted-data.csv', index=False)\n    print(\"Results saved to 'ptge_spaze_angular_error_results-clean-corrupted-data.csv'.\")\n\n# Define subjects\nsubjects = ['p00']\n\n# Evaluate and save angular error results\nevaluate_and_save_angular_error_results(subjects)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T01:11:13.123689Z","iopub.execute_input":"2024-07-16T01:11:13.124161Z","iopub.status.idle":"2024-07-16T01:18:32.281347Z","shell.execute_reply.started":"2024-07-16T01:11:13.124097Z","shell.execute_reply":"2024-07-16T01:18:32.280254Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Evaluating for subject: p00\nPTGE Clean Angular Error: 96.10797342936198\nPTGE Corrupted Angular Error (Noise): 96.10800799560546\nPTGE Corrupted Angular Error (Blur): 96.1067521870931\nSPAZE Clean Angular Error: 79.62430246988933\nSPAZE Corrupted Angular Error (Noise): 74.22585896046957\nSPAZE Corrupted Angular Error (Blur): 80.8032314453125\nResults saved to 'ptge_spaze_angular_error_results-clean-corrupted-data.csv'.\n","output_type":"stream"}]}]}